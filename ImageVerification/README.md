In this project, I trained my model to make decisions on food taste similarity based on images and human judgements. Given a dataset of images of 10.000 dishes and a set of triplets (A, B, C) representing human annotations, in which the human annotator judged that the taste of dish A is more similar to the taste of dish B than to the taste of dish C, I attempted to have the model categorize unseen triplets.

Following a Stanford tutorial on data generation, I loaded data in partitions to most effectively access the image data without depleting my computer memory.  After reading a few papers about image verification, I decided to try a network with triplet loss in which I mapped the distances between A and B and A and C, anchor with positive and anchor with negative respectively, to create a lower-dimensional classification problem.  Then, following a suggestion from the tutorial Imputation and CNN, I decided also to use a pre-trained model.  The one that seemed easiest to implement and most suited to my needs was TensorFlowâ€™s NasNetMobile.  (I also tried MobileNet, a smaller pre-trained model base, and did not achieve as good results as with NasNet.) I froze the weights of the pre-trained model and just added embedding, concatenation, and dense layers on top of the pre-trained model.  Originally, I had more than 2 million trainable parameters, which led to some overfitting issues and very long training periods, and chose to freeze and tie more weights so that only 170,000 or so parameters were trainable.  Overall, the final model has essentially three sub-models: the pre-trained model, the embedding/PCA, and the Classification model.  I also considered, though eventually phased out, a Siamese network.
